# ğŸ Python Backend - Sistema RAG SIAN

Backend FastAPI para o chatbot SIAN com sistema RAG (Retrieval-Augmented Generation) e processamento multimodal.

## âœ¨ CaracterÃ­sticas

- ğŸ¤– **RAG AvanÃ§ado**: Sistema de recuperaÃ§Ã£o e geraÃ§Ã£o aumentada com mÃºltiplos modelos
- ğŸ” **Busca HÃ­brida**: Combina busca vetorial e lexical (BM25, TF-IDF, Elasticsearch)
- ğŸ“„ **Processamento Multimodal**: Suporte para PDF, Ã¡udio, vÃ­deo, imagens e URLs
- ğŸ™ï¸ **TranscriÃ§Ã£o**: TranscriÃ§Ã£o de Ã¡udio e vÃ­deo com Gemini
- âš¡ **Streaming SSE**: Respostas em tempo real com Server-Sent Events
- ğŸ”„ **Retry AutomÃ¡tico**: Sistema robusto de retry para APIs externas
- ğŸ“Š **MÃºltiplos Modelos**: Flash (rÃ¡pido) e Thinking (preciso)

## ğŸš€ Tecnologias

### Core
- **FastAPI** - Framework web assÃ­ncrono
- **Python 3.10+** - Linguagem principal
- **Uvicorn** - Servidor ASGI de alta performance

### IA e LLM
- **Google Gemini 2.5 Flash** - Modelo de linguagem principal
- **Multilingual Instruct** - Embeddings multilingues

### Busca e IndexaÃ§Ã£o
- **Elasticsearch 8.11** - Motor de busca distribuÃ­do
- **Oracle Database** - Banco de dados principal

### Processamento
- **BeautifulSoup4** - Web scraping
- **imageio-ffmpeg** - Processamento de vÃ­deo

## ğŸ“¦ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone [url-do-repositorio]

# Entre no diretÃ³rio
cd python-backend-2

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Instale dependÃªncias
pip install -r requirements.txt

# Configure variÃ¡veis de ambiente
cp .env.example .env
# Edite .env com suas credenciais

# Inicie o servidor
python main.py
```

## ğŸ› ï¸ Estrutura do Projeto

```
python-backend-2/
â”œâ”€â”€ api/                      # Camada de API
â”‚   â”œâ”€â”€ api_service.py       # LÃ³gica de negÃ³cio
â”‚   â”œâ”€â”€ models.py            # Modelos Pydantic
â”‚   â””â”€â”€ routers.py           # Endpoints HTTP
â”œâ”€â”€ processors/              # Processadores de arquivos
â”‚   â”œâ”€â”€ audio_processor.py   # Processamento de Ã¡udio
â”‚   â”œâ”€â”€ audio_transcriber.py # TranscriÃ§Ã£o de Ã¡udio
â”‚   â”œâ”€â”€ image_processor.py   # Processamento de imagens
â”‚   â”œâ”€â”€ pdf_processor.py     # Processamento de PDFs
â”‚   â”œâ”€â”€ video_processor.py   # Processamento de vÃ­deos
â”‚   â”œâ”€â”€ video_transcriber.py # TranscriÃ§Ã£o de vÃ­deos
â”‚   â”œâ”€â”€ url_processor_backend.py  # Processamento de URLs
â”‚   â””â”€â”€ youtube_url_processor.py  # Processamento de YouTube
â”œâ”€â”€ rag_models/              # Modelos RAG
â”‚   â”œâ”€â”€ flash/              # Modelo rÃ¡pido
â”‚   â”‚   â”œâ”€â”€ config.py       # ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ messages.py     # Mensagens de progresso
â”‚   â”‚   â”œâ”€â”€ pipeline.py     # Pipeline principal
â”‚   â”‚   â”œâ”€â”€ query_engine.py # Motor de consulta
â”‚   â”‚   â”œâ”€â”€ query.py        # Handler de consultas
â”‚   â”‚   â””â”€â”€ utils.py        # UtilitÃ¡rios
â”‚   â”œâ”€â”€ thinking/           # Modelo avanÃ§ado
â”‚   â”‚   â”œâ”€â”€ config.py       # ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ messages.py     # Mensagens de progresso
â”‚   â”‚   â”œâ”€â”€ pipeline.py     # Pipeline principal
â”‚   â”‚   â”œâ”€â”€ query_engine.py # Motor de consulta
â”‚   â”‚   â”œâ”€â”€ query.py        # Handler de consultas
â”‚   â”‚   â””â”€â”€ validation.py   # ValidaÃ§Ã£o de respostas
â”‚   â””â”€â”€ multimodal/         # Modelo multimodal
â”‚       â”œâ”€â”€ config.py       # ConfiguraÃ§Ãµes
â”‚       â”œâ”€â”€ messages.py     # Mensagens de progresso
â”‚       â”œâ”€â”€ pipeline.py     # Pipeline principal
â”‚       â”œâ”€â”€ query_engine.py # Motor de consulta
â”‚       â”œâ”€â”€ query.py        # Handler de consultas
â”‚       â””â”€â”€ utils.py        # UtilitÃ¡rios
â”œâ”€â”€ search_algorithms/       # Algoritmos de busca
â”‚   â”œâ”€â”€ bm25_search.py      # BM25 tradicional
â”‚   â”œâ”€â”€ bm25p_search.py     # BM25+ otimizado
â”‚   â”œâ”€â”€ elasticsearch_search.py  # Busca Elasticsearch
â”‚   â”œâ”€â”€ lambdamart_search.py     # LambdaMART ranking
â”‚   â”œâ”€â”€ simple_like_search.py    # Busca SQL LIKE
â”‚   â”œâ”€â”€ tfidf_search.py     # TF-IDF
â”‚   â””â”€â”€ vector_search.py    # Busca vetorial
â”œâ”€â”€ main.py                 # Ponto de entrada
â”œâ”€â”€ config.py               # ConfiguraÃ§Ã£o global
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â””â”€â”€ README.md              # Este arquivo
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente (.env)

```env
# API Keys
GEMINI_API=sua_chave_gemini
GOOGLE_API_KEY=sua_chave_google

# Oracle Database
ORACLE_USER=usuario
ORACLE_PASSWORD=senha
ORACLE_DSN=host:porta/servico

# Elasticsearch
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200

# Proxy (opcional)
PROXY=http://proxy:porta
```

## ğŸ“¡ Endpoints da API

### Chat e Consultas

#### POST /ask-stream-flash
Consulta rÃ¡pida com streaming (modelo Flash)
```json
{
  "consulta": "Busque documentos sobre...",
  "historico": [
    {"usuario": "pergunta", "bot": "resposta"}
  ]
}
```

#### POST /ask-stream
Consulta avanÃ§ada com streaming (modelo Thinking)
```json
{
  "consulta": "Busque documentos sobre...",
  "historico": [...]
}
```

#### POST /ask-file-stream
Consulta multimodal com arquivo anexado
```json
{
  "consulta": "Analise este documento",
  "metadata": {
    "assunto_principal": "tema",
    "termos_chave": ["termo1", "termo2"],
    "resumo": "resumo do arquivo"
  },
  "historico": [...]
}
```

### Processamento de Arquivos

#### POST /process-pdf
Processa arquivo PDF
- **Input**: Arquivo PDF (multipart/form-data)
- **Output**: JSON estruturado para busca

#### POST /process-audio
Processa arquivo de Ã¡udio
- **Input**: Arquivo de Ã¡udio (MP3, M4A, WAV)
- **Output**: JSON estruturado para busca

#### POST /process-video
Processa arquivo de vÃ­deo
- **Input**: Arquivo de vÃ­deo (MP4, AVI, MOV)
- **Output**: JSON estruturado para busca

#### POST /process-image
Processa arquivo de imagem
- **Input**: Arquivo de imagem (JPG, PNG, WEBP)
- **Output**: JSON estruturado para busca

#### POST /process-url
Processa URL de pÃ¡gina web
```json
{
  "url": "https://exemplo.com/artigo"
}
```

### TranscriÃ§Ã£o

#### POST /transcribe-audio
Transcreve Ã¡udio com streaming
- **Input**: Arquivo de Ã¡udio
- **Output**: Stream SSE com transcriÃ§Ã£o

#### POST /transcribe-video
Transcreve vÃ­deo com streaming
- **Input**: Arquivo de vÃ­deo
- **Output**: Stream SSE com transcriÃ§Ã£o

## ğŸ¯ Modelos RAG

### Flash (RÃ¡pido)
- **Uso**: Consultas simples e rÃ¡pidas
- **LatÃªncia**: ~2-5 segundos
- **PrecisÃ£o**: Boa
- **Busca**: Vetorial + BM25

### Thinking (AvanÃ§ado)
- **Uso**: Consultas complexas e precisas
- **LatÃªncia**: ~5-15 segundos
- **PrecisÃ£o**: Excelente
- **Busca**: Vetorial + BM25 + ValidaÃ§Ã£o JSON

### Multimodal
- **Uso**: Consultas com arquivos anexados
- **LatÃªncia**: VariÃ¡vel (depende do arquivo)
- **PrecisÃ£o**: Excelente
- **Busca**: Vetorial + BM25 + AnÃ¡lise de conteÃºdo

## ğŸ” Sistema de Busca

### Busca Vetorial
- **Modelo**: Multilingual Instruct
- **DimensÃµes**: 768
- **Similaridade**: Cosseno
- **Top-K**: ConfigurÃ¡vel

### Busca Lexical
- **BM25**: Ranking probabilÃ­stico
- **BM25+**: VersÃ£o otimizada
- **TF-IDF**: FrequÃªncia de termos
- **Elasticsearch**: Motor distribuÃ­do

### Busca HÃ­brida
Combina resultados de busca vetorial e lexical com pesos configurÃ¡veis para melhor precisÃ£o.

## ğŸ“Š Processamento Multimodal

### PDF
1. ExtraÃ§Ã£o de texto com PyPDF2
2. AnÃ¡lise de conteÃºdo com Gemini
3. GeraÃ§Ã£o de termos-chave e resumo
4. CriaÃ§Ã£o de query estruturada

### Ãudio
1. Upload para Gemini File API
2. AnÃ¡lise direta com Gemini 2.0 Flash Lite
3. ExtraÃ§Ã£o de assunto, termos e resumo
4. GeraÃ§Ã£o de query estruturada

### VÃ­deo
1. Upload para Gemini File API
2. AnÃ¡lise de Ã¡udio e vÃ­deo com Gemini
3. ExtraÃ§Ã£o de informaÃ§Ãµes multimodais
4. GeraÃ§Ã£o de query estruturada

### Imagem
1. Upload para Gemini File API
2. AnÃ¡lise visual com Gemini Vision
3. ExtraÃ§Ã£o de contexto e elementos
4. GeraÃ§Ã£o de query estruturada

### URL
1. Web scraping com BeautifulSoup
2. ExtraÃ§Ã£o de conteÃºdo principal
3. AnÃ¡lise com Gemini
4. GeraÃ§Ã£o de query acadÃªmica

## âš¡ Streaming SSE

O sistema utiliza Server-Sent Events para streaming em tempo real:

### Eventos
- **progress**: Mensagens de progresso
- **partial**: Resposta parcial do LLM
- **done**: Resultado final
- **error**: Mensagens de erro
- **chunk**: Chunks de transcriÃ§Ã£o

### Exemplo de Resposta
```
event: progress
data: Buscando documentos relevantes...

event: progress
data: Encontrados 15 documentos

event: partial
data: Com base nos documentos...

event: done
data: {"resposta": "...", "links": [...]}
```

## ğŸ”„ Sistema de Retry

Implementa retry automÃ¡tico com backoff exponencial:
- **Tentativas**: 10 mÃ¡ximo
- **Intervalos**: 1, 3, 5, 7, 9, 11, 13, 15, 17, 19 segundos
- **Timeout**: 300 segundos por chamada
- **Fallback**: Mensagem de erro amigÃ¡vel

## ğŸ³ Docker

```bash
# Build da imagem
docker build -t sian-backend .

# Executar container
docker run -p 8000:8000 --env-file .env sian-backend

# Docker Compose
docker-compose up -d
```

## ğŸ“ Logs

O sistema gera logs detalhados para debug:
- RequisiÃ§Ãµes HTTP
- Processamento de arquivos
- Chamadas LLM
- Erros e exceÃ§Ãµes
- Performance

## ğŸ§ª Testes

```bash
# Executar testes
python -m pytest

# Teste de endpoint especÃ­fico
python test.py

# Teste de processador de URL
python test_url_processor.py
```

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a [MIT](LICENSE).

## ğŸ›ï¸ Sobre

Desenvolvido para o **Arquivo Nacional** como parte do sistema SIAN, fornecendo backend robusto para consultas arquivÃ­sticas inteligentes com IA.

---

**SIAN Backend** â€¢ *Sistema Inteligente de Arquivos Nacionais* â€¢ Dataprev Â© 2025
