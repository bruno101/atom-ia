# Processador de URLs - Web Scraping + LLM

## Vis√£o Geral

Este sistema permite processar URLs de p√°ginas web, extrair conte√∫do atrav√©s de web scraping e usar LLM para gerar consultas estruturadas para literatura acad√™mica.

## Componentes

### 1. Frontend (JavaScript)
- **Arquivo**: `chatbot-frontend/src/features/fileUpload/fileProcessor.js`
- **M√©todo**: `processURL(url)`
- **Fun√ß√£o**: Envia URL para o backend e recebe JSON estruturado

### 2. Web Scraper (Python)
- **Arquivo**: `web_scraper.py`
- **Fun√ß√£o**: Extrai conte√∫do textual de p√°ginas web usando BeautifulSoup
- **Sa√≠da**: JSON com t√≠tulo, conte√∫do, links e metadados

### 3. Processador Backend (Python)
- **Arquivo**: `processors/url_processor_backend.py`
- **Fun√ß√£o**: Usa LLM (Gemini) para extrair informa√ß√µes acad√™micas
- **Sa√≠da**: JSON estruturado para consulta acad√™mica

### 4. API Endpoints
- **POST /process-url**: Processa URL e retorna JSON estruturado
- **POST /ask-url-stream**: Executa consulta baseada em URL processada

## Fluxo de Processamento

```
URL ‚Üí Web Scraping ‚Üí LLM Processing ‚Üí Structured JSON ‚Üí Academic Query
```

### Feedback Visual
- **Frontend**: Barra de progresso com 4 etapas
- **Backend**: Logs detalhados no terminal

## Estrutura do JSON de Sa√≠da

```json
{
  "query_id": "AUTO_AUDIT_QUERY-20241220_143022",
  "search_target": "ACADEMIC_LITERATURE",
  "conte√∫do": "[CONTE√öDO DA P√ÅGINA]",
  "url": "[URL DA P√ÅGINA]",
  "input_busca": "[TERMOS DE BUSCA EXTRA√çDOS]",
  "filters": {
    "main_subject": "[ASSUNTO PRINCIPAL]",
    "author_names": ["autor1", "autor2"],
    "publication_year_min": 2024,
    "keywords_must_contain": ["palavra1", "palavra2"]
  },
  "sort_by": "relevance",
  "max_results": 10,
  "return_fields": ["title", "abstract_snippet", "publication_link"]
}
```

## Como Usar

### Frontend (JavaScript)
```javascript
import { processURL } from './fileProcessor.js';

const url = 'https://example.com/academic-paper';
try {
  const structuredQuery = await processURL(url);
  // Barra de progresso autom√°tica:
  // üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% - Processamento conclu√≠do!
  console.log('Query gerada:', structuredQuery);
} catch (error) {
  console.error('Erro:', error.message);
}
```

### Backend (Python)
```python
# Teste direto
from processors.url_processor_backend import process_url_data
from web_scraper import scrape_webpage

url = "https://example.com"
scraped_data = scrape_webpage(url)
structured_query = process_url_data(scraped_data)
```

### API REST
```bash
# Processar URL
curl -X POST "http://localhost:8000/process-url" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

## Depend√™ncias

### Python
- `requests`: Para requisi√ß√µes HTTP
- `beautifulsoup4`: Para parsing HTML
- `google.generativeai`: Para processamento LLM
- `python-dotenv`: Para vari√°veis de ambiente

### Instala√ß√£o
```bash
pip install requests beautifulsoup4
```

## Logs do Sistema

### Frontend (Console)
```
üîÑ Iniciando processamento da URL: https://example.com
üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 25% - Enviando URL para processamento...
üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 50% - Recebendo resposta do servidor...
üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë] 75% - Processando dados com LLM...
üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% - Processamento conclu√≠do!
‚úÖ URL processada com sucesso
```

### Backend (Terminal)
```
üîç Fazendo scraping da URL: https://example.com
üåê Baixando conte√∫do da p√°gina...
‚úÖ Download conclu√≠do
üìù Analisando HTML...
‚úÖ An√°lise HTML conclu√≠da
‚úÖ Scraping conclu√≠do - Extra√≠dos 2847 caracteres
üîÑ Iniciando processamento dos dados...
ü§ñ Extraindo informa√ß√µes com LLM...
‚úÖ Extra√ß√£o LLM conclu√≠da
üìù Montando JSON estruturado...
‚úÖ JSON estruturado criado com sucesso

================================================================================
üåê JSON ESTRUTURADO GERADO PARA CONSULTA ACAD√äMICA
================================================================================
üîó URL Processada: https://example.com
üéØ Assunto Principal: Machine Learning
üîç Termos de Busca: machine learning algorithms
üìÖ Query ID: AUTO_AUDIT_QUERY-20241220_143022
--------------------------------------------------------------------------------
JSON COMPLETO:
{
  "query_id": "AUTO_AUDIT_QUERY-20241220_143022",
  ...
}
================================================================================
```

## Configura√ß√£o

1. Configure a API key do Google Gemini no arquivo `.env`:
```
GOOGLE_API_KEY=sua_api_key_aqui
```

2. Certifique-se de que o servidor FastAPI est√° rodando na porta 8000

## Teste

Execute o script de teste:
```bash
python test_url_processor.py https://example.com
```

## Recursos Visuais

### Barra de Progresso
- 4 etapas de processamento
- Indicador visual com percentual
- Mensagens descritivas de cada fase

### Logs Estruturados
- **Web Scraper**: Progresso do download e an√°lise
- **LLM Processor**: Status da extra√ß√£o de informa√ß√µes
- **API**: Resumo detalhado do JSON gerado

## Limita√ß√µes

- Funciona melhor com p√°ginas de conte√∫do acad√™mico
- Requer conex√£o com internet para scraping e LLM
- Limitado por rate limits das APIs utilizadas
- Alguns sites podem bloquear scraping automatizado

## Tratamento de Erros

O sistema inclui tratamento robusto de erros:
- Timeout de requisi√ß√µes (30s)
- Fallback para dados b√°sicos se LLM falhar
- Logs detalhados para debugging
- Respostas de erro estruturadas
- Feedback visual de erros na barra de progresso